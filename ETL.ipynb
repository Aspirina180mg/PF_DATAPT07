{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Extracción de datos Datasets Google Maps y YELP\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Importaciones\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import datetime\n",
                "import os\n",
                "import pyarrow.parquet as pq\n",
                "from datetime import datetime"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Utiles\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "state_abreviations = [\n",
                "    \"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\n",
                "    \"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\n",
                "    \"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\n",
                "    \"VA\",\"WA\",\"WV\",\"WI\",\"WY\",\n",
                "]\n",
                "\n",
                "state_dictionary = {\n",
                "    \"AL\": \"Alabama\",\"AK\": \"Alaska\",\"AZ\": \"Arizona\",\"AR\": \"Arkansas\",\n",
                "    \"CA\": \"California\",\"CO\": \"Colorado\",\"CT\": \"Connecticut\",\"DE\": \"Delaware\",\n",
                "    \"FL\": \"Florida\",\"GA\": \"Georgia\",\"HI\": \"Hawaii\",\"ID\": \"Idaho\",\n",
                "    \"IL\": \"Illinois\",\"IN\": \"Indiana\",\"IA\": \"Iowa\",\"KS\": \"Kansas\",\n",
                "    \"KY\": \"Kentucky\",\"LA\": \"Louisiana\",\"ME\": \"Maine\",\"MD\": \"Maryland\",\n",
                "    \"MA\": \"Massachusetts\",\"MI\": \"Michigan\",\"MN\": \"Minnesota\",\n",
                "    \"MS\": \"Mississippi\",\"MO\": \"Missouri\",\"MT\": \"Montana\",\"NE\": \"Nebraska\",\n",
                "    \"NV\": \"Nevada\",\"NH\": \"New Hampshire\",\"NJ\": \"New Jersey\",\"NM\": \"New Mexico\",\n",
                "    \"NY\": \"New York\",\"NC\": \"North Carolina\",\"ND\": \"North Dakota\",\"OH\": \"Ohio\",\n",
                "    \"OK\": \"Oklahoma\",\"OR\": \"Oregon\",\"PA\": \"Pennsylvania\",\"RI\": \"Rhode Island\",\n",
                "    \"SC\": \"South Carolina\",\"SD\": \"South Dakota\",\"TN\": \"Tennessee\",\n",
                "    \"TX\": \"Texas\",\"UT\": \"Utah\",\"VT\": \"Vermont\",\"VA\": \"Virginia\",\n",
                "    \"WA\": \"Washington\",\"WV\": \"West Virginia\",\"WI\": \"Wisconsin\",\"WY\": \"Wyoming\",\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "generated_dir = \"Generated\"\n",
                "\n",
                "os.mkdir(generated_dir)\n",
                "os.chdir(generated_dir)\n",
                "os.mkdir(\"Google\")\n",
                "os.mkdir(\"Yelp\")\n",
                "os.chdir(\"../\")\n",
                "\n",
                "os.getcwd()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Extracción con los datasets de Google Maps\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.1 Metada de Sitios\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Recorremos todo el directorio, lo hacemos archivo por archivo y línea por línea ya que no se puede abrir directamente los archivos por su dimensión y porque no están en formato de array, sino están constituidos en un registro por lìnea.\n",
                "Durante la lectura filtramos los que incluyan <code>Restaurant</code> en el campo de categoría, para alivianar el dataset final.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tiempo de Demora Medio: 51 segundos.\n",
                "lineas_json = []\n",
                "\n",
                "# Son 11 archivos con un ordinal, del 1 al 11\n",
                "for i in range(1, 12):\n",
                "    path = f\"Datasets/Google Maps/metadata-sitios/{i}.json\"\n",
                "    with open(path, \"r\") as file:\n",
                "        for l in file:\n",
                "            try:\n",
                "                linea_j = json.loads(l)\n",
                "                if \"restaurant\" in \" \".join(linea_j[\"category\"]).lower():\n",
                "                    lineas_json.append(linea_j)\n",
                "            except:\n",
                "                pass\n",
                "\n",
                "df = pd.DataFrame(lineas_json)\n",
                "\n",
                "df.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.loc[5, 'address']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Exportamos a formato Parquet\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.to_parquet(r\"Generated\\Google\\metada_sitios.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tamaño Directorio <code>metadata-sitios</code>: 2.76 Gb\n",
                "\n",
                "Tamaño Archivo <code>metada_sitios.parquet</code>: 60.43 Mb\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dimensiones: 212.014 filas x 15 Columnas\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.1.1 Obtención de información de Estados\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "En base al campo <code>Address</code> obtenemos el estado donde se encuentra el negocio. Nos servirá para luego seleccionar los estados con más restaurantes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_state_ab(st):\n",
                "    try:\n",
                "        state = st.split(\", \")[-1].split(\" \")[0]\n",
                "        if state in state_abreviations:\n",
                "            return state\n",
                "        else:\n",
                "            return np.nan\n",
                "    except:\n",
                "        return np.nan\n",
                "\n",
                "\n",
                "df[\"state_ab\"] = df[\"address\"].apply(get_state_ab)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "De esta manera conseguimos el top 5 de los estados con más restaurantes\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "top_5 = df[\"state_ab\"].value_counts().head(5).index.to_list()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "top_5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Completamos el campo estado que es más descriptivo\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df[\"us_state\"] = df[\"state_ab\"].map(state_dictionary)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['us_state'].head(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Obtenemos un arreglo de URLs de los archivos correspondientes para cada estado del top 5, con el fin de extraer los datos en un bucle.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "top_5_url = [f\"Datasets/Google Maps/reviews-estados/review-{state_dictionary[i].replace(' ', '_')}/\" for i in top_5]\n",
                "\n",
                "top_5_url\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Creamos un diccionario con la cantidad de archivos por cada directorio de estados, con el fin de utilizarlo en un bucle en la extracción de datos.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cantidad_archivos = {}\n",
                "\n",
                "for i in top_5_url:\n",
                "    for j in os.walk(i):\n",
                "        cantidad_archivos[i] = len(j[2])\n",
                "\n",
                "cantidad_archivos"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Comprobación\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in os.walk('Datasets/Google Maps/reviews-estados/review-Pennsylvania'):\n",
                "    print(len(i[2]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cantidad_archivos['Datasets/Google Maps/reviews-estados/review-Pennsylvania/']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.2 Reviews Estados\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ya con los estados elegidos estamos en condiciones de ingestar los datos de las carpetas correspondientes dentro del directorio <code>reviews-estados</code>.\n",
                "Es información masiva lo que genera un archivo de grandes dimensiones, sin embargo previamente filtramos por el parámetro de año <code>2017-2019</code> valiéndonos del campo <code>time</code>, que tiene es un <code>timestamp</code>, pero con 3 digitos más que el usado por <code>datetime</code> de Python. Le agregamos el campo <code>Estado</code> que es más descriptivo.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Demora 7 minutos y 40 segundos, 11 minutos, varía\n",
                "\n",
                "lineas_json_revs_google = []\n",
                "\n",
                "for i in top_5_url:\n",
                "    count = 0\n",
                "    for c in range(1, cantidad_archivos[i] + 1):\n",
                "        with open(str(i) + str(c) + \".json\", \"r\", encoding=\"utf-8\") as f:\n",
                "            for s in f:\n",
                "                linea = json.loads(s)\n",
                "                linea[\"anio\"] = datetime.datetime.fromtimestamp(\n",
                "                    linea[\"time\"] / 1000\n",
                "                ).year\n",
                "                linea[\"estado\"] = i.split(\"-\")[-1][:-1]\n",
                "\n",
                "                if linea[\"anio\"] in [2017, 2018, 2019]:\n",
                "                    lineas_json_revs_google.append(linea)\n",
                "\n",
                "df_revs_google = pd.DataFrame(lineas_json_revs_google)\n",
                "\n",
                "df_revs_google.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merge_site_reviews = pd.merge(df_revs_google, df, left_on=\"gmap_id\", right_on=\"gmap_id\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merge_site_reviews"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merge_site_reviews.to_parquet(r\"Generated\\Google\\merge_site_reviews.parquet\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_revs_google.to_parquet(r\"Generated\\Google\\reviews-estados.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tamaño archivo: 760 Mb\n",
                "\n",
                "Tamaño dataset: 24.3 Gb\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_revs_google.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tamaño 8.339.179 filas x 10 Columnas.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Extracción de los Dataset de YELP\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Business\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Contiene los datos de las entidades negocios de Yelp, a un primer vistazo tiene las columnas duplicadas, por lo que hay que hacer un recorte, ya que la segunda mitad tiene datos vacíos en su inmensa mayoría.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "url_business = r\"Datasets\\Yelp\\business.pkl\"\n",
                "\n",
                "df_business = pd.read_pickle(url_business)\n",
                "\n",
                "df_business = df_business.iloc[:, :-14]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_business.sample(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_business.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Luego con la ayuda del campo <code>state</code> filtramos los negocios que se encuentran en los estados seleccionados en nuestro análisis.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_business = df_business[df_business.state.isin(top_5)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_business.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Seguimos filtrando a través del campo <code>categories</code>, para obtener los negocios que son restaurantes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def is_restaurant(st):\n",
                "    try:\n",
                "        test = \"\".join(st).lower()\n",
                "        return \"restaurant\" in test\n",
                "    except:\n",
                "        return False\n",
                "\n",
                "\n",
                "df_business = df_business[df_business[\"categories\"].apply(is_restaurant)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_business.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_business.to_parquet(r\"Generated\\Yelp\\bussines.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Checkin\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lineas_json = []\n",
                "path_checkin = r\"Datasets\\Yelp\\checkin.json\"\n",
                "with open(path_checkin, \"r\", encoding=\"utf-8\") as file:\n",
                "    for l in file:\n",
                "        try:\n",
                "            linea_j = json.loads(l)\n",
                "            anio = linea_j[\"date\"][:4]\n",
                "            # if 'restaurant' in \" \".join(linea_j['category']).lower():\n",
                "            if anio in [\"2017\", \"2018\", \"2019\"]:\n",
                "                lineas_json.append(linea_j)\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "df_checkin = pd.DataFrame(lineas_json)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_checkin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merge_business_checkin = pd.merge(\n",
                "    df_business, df_checkin, left_on=\"business_id\", right_on=\"business_id\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merge_business_checkin.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_checkin.to_parquet(r\"Generated\\Yelp\\checkin.parquet\")\n",
                "merge_business_checkin.to_parquet(r\"Generated\\YELP\\business_checkin.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Tips\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Realizamos la extracción de los datos y filtramos por año según nuestro análisis.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lineas_json = []\n",
                "path_tip = r\"Datasets\\Yelp\\tip.json\"\n",
                "with open(path_tip, \"r\", encoding=\"utf-8\") as file:\n",
                "    for l in file:\n",
                "        try:\n",
                "            linea_j = json.loads(l)\n",
                "            anio = linea_j[\"date\"][:4]\n",
                "            if anio in [\"2017\", \"2018\", \"2019\"]:\n",
                "                lineas_json.append(linea_j)\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "df_tip = pd.DataFrame(lineas_json)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_tip.sample(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_tip.to_parquet(r\"Generated\\Yelp\\tip.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Unimos el el dataframe de tips con el de negocios\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tips_merged = pd.merge(\n",
                "    df_tip, df_business, left_on=\"business_id\", right_on=\"business_id\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tips_merged.sort_values(\"business_id\").head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tips_merged.to_parquet(r\"Generated\\Yelp\\business_tip.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Review\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_reviews_url = r\"Datasets\\Yelp\\review.json\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Usamos el mismo método de linea por linea, y en el proceso filtramos por año y por las reseñas que han sido votadas como útiles.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 44 segundos\n",
                "\n",
                "lineas_json_review = []\n",
                "\n",
                "with open(df_reviews_url, \"r\", encoding=\"utf-8\") as f:\n",
                "    count = 0\n",
                "    for i in f:\n",
                "        linea = json.loads(i)\n",
                "        anio = linea[\"date\"][:4]\n",
                "        if anio in [\"2017\", \"2018\", \"2019\"] and linea[\"useful\"] == 1:\n",
                "            lineas_json_review.append(linea)\n",
                "\n",
                "\n",
                "df_reviews = pd.DataFrame(lineas_json_review)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_reviews.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_reviews.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Aligeramos el dataset con unos downgrades de tipo de variables.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_reviews[\"funny\"] = df_reviews[\"funny\"].astype(\"int8\")\n",
                "df_reviews[\"stars\"] = df_reviews[\"stars\"].astype(\"int8\")\n",
                "df_reviews[\"cool\"] = df_reviews[\"cool\"].astype(\"int8\")\n",
                "\n",
                "df_reviews.drop(\"useful\", axis=1, inplace=True, errors=\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_reviews.to_parquet(r\"Generated\\Yelp\\review.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Users Yelp\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "parquet_file = pq.ParquetFile(r\"Datasets\\Yelp\\user.parquet\")\n",
                "\n",
                "arr_df = []\n",
                "\n",
                "for batch in parquet_file.iter_batches():\n",
                "    # count = count +1\n",
                "    batch_df = batch.to_pandas()\n",
                "    batch_df[\"elite\"] = batch_df[\"elite\"].apply(lambda x: x.split(\",\"))\n",
                "    batch_df[\"elite_len\"] = batch_df[\"elite\"].apply(lambda x: len(x))\n",
                "    batch_df = batch_df.query(\"elite_len > 1\")\n",
                "    arr_df.append(batch_df)\n",
                "\n",
                "df_users = pd.concat(arr_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_users.sample(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_users.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_users.reset_index(inplace=True)\n",
                "df_users.drop(\"index\", axis=1, inplace=True, errors=\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_users.to_parquet(r\"Generated\\Yelp\\users_extracted.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# NORMALIZACIÓN DE DATOS\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **GOOGLE**\n",
                "\n",
                "#### _1. MERGE_SITE_REVIEWS_\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_restaurantes = pd.read_parquet(r'Generated\\Google\\metada_sitios.parquet')\n",
                "df_maps_reviews = pd.read_parquet(r'Generated\\Google\\merge_site_reviews.parquet')\n",
                "df_yelp_restaurantes = pd.read_parquet(r'Generated\\Yelp\\bussines.parquet')\n",
                "df_yelp_checkin = pd.read_parquet(r'Generated\\YELP\\business_checkin.parquet')\n",
                "df_yelp_tips = pd.read_parquet(r'Generated\\Yelp\\business_tip.parquet')\n",
                "df_yelp_reviews = pd.read_parquet(r'Generated\\Yelp\\review.parquet')\n",
                "df_yelp_users = pd.read_parquet(r'Generated\\Yelp\\users_extracted.parquet')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_reviews.sample(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_reviews.columns.values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_reviews.category"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_reviews.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_reviews[~df_maps_reviews.pics.isnull()].sample(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_nulls_pics = df_maps_reviews.pics.isnull().sum()\n",
                "num_nulls_pics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_nulls_resp = df_maps_reviews.resp.isnull().sum()\n",
                "num_nulls_resp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_reviews[\"dtfmt\"] = df_maps_reviews.time.apply(\n",
                "    lambda x: datetime.utcfromtimestamp(x / 1000)\n",
                ")\n",
                "\n",
                "df_maps_reviews[\"mes\"] = df_maps_reviews.dtfmt.dt.month\n",
                "\n",
                "df_maps_reviews[\"dia\"] = df_maps_reviews.dtfmt.dt.day\n",
                "\n",
                "df_maps_reviews[\"hora\"] = df_maps_reviews.dtfmt.dt.hour\n",
                "\n",
                "df_maps_reviews.name_x = df_maps_reviews.name_x.str.title()\n",
                "\n",
                "df_maps_reviews.text = df_maps_reviews.text.str.lower()\n",
                "\n",
                "df_maps_reviews.sample(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **_<u>COMENTARIO</u>_**\n",
                "\n",
                "Las columnas **pics** y **resp** deberían eliminarse porque la cantidades de datos nulos sobrepasa los 90%.\n",
                "\n",
                "_Obtenemos las columnas de año, mes, día y hora para posteriores análisis_\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Salida Final ETL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_maps_restaurantes.to_parquet(r'Generated\\Google\\metada_sitios.parquet')\n",
                "df_maps_reviews.to_parquet(r'Generated\\Google\\merge_site_reviews.parquet')\n",
                "df_yelp_restaurantes.to_parquet(r'Generated\\Yelp\\bussines.parquet')\n",
                "df_yelp_checkin.to_parquet(r'Generated\\YELP\\business_checkin.parquet')\n",
                "df_yelp_tips.to_parquet(r'Generated\\Yelp\\business_tip.parquet')\n",
                "df_yelp_reviews.to_parquet(r'Generated\\Yelp\\review.parquet')\n",
                "df_yelp_users.to_parquet(r'Generated\\Yelp\\users_extracted.parquet')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
