{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de datos Datasets Google Maps y YELP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_abreviations = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \n",
    "    \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \n",
    "    \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \n",
    "    \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \n",
    "    \"WI\", \"WY\"\n",
    "]\n",
    "\n",
    "state_dictionary = {\n",
    "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \n",
    "    \"CA\": \"California\", \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \n",
    "    \"FL\": \"Florida\", \"GA\": \"Georgia\", \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \n",
    "    \"IN\": \"Indiana\", \"IA\": \"Iowa\", \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \n",
    "    \"ME\": \"Maine\", \"MD\": \"Maryland\", \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \n",
    "    \"MN\": \"Minnesota\", \"MS\": \"Mississippi\", \"MO\": \"Missouri\", \"MT\": \"Montana\", \n",
    "    \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\", \n",
    "    \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\", \"ND\": \"North Dakota\", \n",
    "    \"OH\": \"Ohio\", \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \n",
    "    \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\", \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \n",
    "    \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\", \"VA\": \"Virginia\", \"WA\": \"Washington\", \n",
    "    \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z:\\\\PF_DATAPT07'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "generated_dir = \"Generated\"\n",
    "\n",
    "os.mkdir(generated_dir)\n",
    "os.chdir(generated_dir)\n",
    "os.mkdir('Google')\n",
    "os.mkdir('Yelp')\n",
    "os.chdir('../')\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracción  con los datasets de Google Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Metada de Sitios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorremos todo el directorio, lo hacemos archivo por archivo y línea por línea ya que no se puede abrir directamente los archivos por su dimensión y porque no están en formato de array, sino están constituidos en un registro por lìnea.\n",
    "Durante la lectura filtramos los que incluyan <code>Restaurant</code> en el campo de categoría, para alivianar el dataset final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>hours</th>\n",
       "      <th>MISC</th>\n",
       "      <th>state</th>\n",
       "      <th>relative_results</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Soo Dang</td>\n",
       "      <td>San Soo Dang, 761 S Vermont Ave, Los Angeles, ...</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "      <td>None</td>\n",
       "      <td>34.058092</td>\n",
       "      <td>-118.292130</td>\n",
       "      <td>[Korean restaurant]</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Thursday, 6:30AM–6PM], [Friday, 6:30AM–6PM],...</td>\n",
       "      <td>{'Service options': ['Takeout', 'Dine-in', 'De...</td>\n",
       "      <td>Open ⋅ Closes 6PM</td>\n",
       "      <td>[0x80c2c78249aba68f:0x35bf16ce61be751d, 0x80c2...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vons Chicken</td>\n",
       "      <td>Vons Chicken, 12740 La Mirada Blvd, La Mirada,...</td>\n",
       "      <td>0x80dd2b4c8555edb7:0xfc33d65c4bdbef42</td>\n",
       "      <td>None</td>\n",
       "      <td>33.916402</td>\n",
       "      <td>-118.010855</td>\n",
       "      <td>[Restaurant]</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Thursday, 11AM–9:30PM], [Friday, 11AM–9:30PM...</td>\n",
       "      <td>{'Service options': ['Outdoor seating', 'Curbs...</td>\n",
       "      <td>Open ⋅ Closes 9:30PM</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sweet Rewards Gluten Free Bakery, LLC</td>\n",
       "      <td>Sweet Rewards Gluten Free Bakery, LLC, 85 NE D...</td>\n",
       "      <td>0x87ec235c54d25b31:0x3b75fb5facc602f</td>\n",
       "      <td>None</td>\n",
       "      <td>41.616079</td>\n",
       "      <td>-93.865487</td>\n",
       "      <td>[Bakery, Health food restaurant]</td>\n",
       "      <td>4.7</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Thursday, 10AM–5:30PM], [Friday, 10AM–5:30PM...</td>\n",
       "      <td>{'Service options': ['Delivery']}</td>\n",
       "      <td>Permanently closed</td>\n",
       "      <td>[0x87ee974869295555:0x95f310d065882c9b, 0x87ec...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  \\\n",
       "0                           San Soo Dang   \n",
       "1                           Vons Chicken   \n",
       "2  Sweet Rewards Gluten Free Bakery, LLC   \n",
       "\n",
       "                                             address  \\\n",
       "0  San Soo Dang, 761 S Vermont Ave, Los Angeles, ...   \n",
       "1  Vons Chicken, 12740 La Mirada Blvd, La Mirada,...   \n",
       "2  Sweet Rewards Gluten Free Bakery, LLC, 85 NE D...   \n",
       "\n",
       "                                 gmap_id description   latitude   longitude  \\\n",
       "0  0x80c2c778e3b73d33:0xbdc58662a4a97d49        None  34.058092 -118.292130   \n",
       "1  0x80dd2b4c8555edb7:0xfc33d65c4bdbef42        None  33.916402 -118.010855   \n",
       "2   0x87ec235c54d25b31:0x3b75fb5facc602f        None  41.616079  -93.865487   \n",
       "\n",
       "                           category  avg_rating  num_of_reviews price  \\\n",
       "0               [Korean restaurant]         4.4              18  None   \n",
       "1                      [Restaurant]         4.5              18  None   \n",
       "2  [Bakery, Health food restaurant]         4.7              21  None   \n",
       "\n",
       "                                               hours  \\\n",
       "0  [[Thursday, 6:30AM–6PM], [Friday, 6:30AM–6PM],...   \n",
       "1  [[Thursday, 11AM–9:30PM], [Friday, 11AM–9:30PM...   \n",
       "2  [[Thursday, 10AM–5:30PM], [Friday, 10AM–5:30PM...   \n",
       "\n",
       "                                                MISC                 state  \\\n",
       "0  {'Service options': ['Takeout', 'Dine-in', 'De...     Open ⋅ Closes 6PM   \n",
       "1  {'Service options': ['Outdoor seating', 'Curbs...  Open ⋅ Closes 9:30PM   \n",
       "2                  {'Service options': ['Delivery']}    Permanently closed   \n",
       "\n",
       "                                    relative_results  \\\n",
       "0  [0x80c2c78249aba68f:0x35bf16ce61be751d, 0x80c2...   \n",
       "1                                               None   \n",
       "2  [0x87ee974869295555:0x95f310d065882c9b, 0x87ec...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "1  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "2  https://www.google.com/maps/place//data=!4m2!3...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiempo de Demora Medio: 51 segundos.\n",
    "lineas_json = []\n",
    "\n",
    "# Son 11 archivos con un ordinal, del 1 al 11\n",
    "for i in range(1, 12):\n",
    "    path = f'Datasets/Google Maps/metadata-sitios/{i}.json'\n",
    "    with open(path, 'r') as file:\n",
    "        for l in file:\n",
    "            try:\n",
    "                linea_j = json.loads(l)\n",
    "                if 'restaurant' in \" \".join(linea_j['category']).lower():\n",
    "                    lineas_json.append(linea_j)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "df = pd.DataFrame(lineas_json)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cape Seafood Shack, 603 Del Prado Blvd S, Cape Coral, FL 33990'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5, 'address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos a formato Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(r'Generated\\Google\\metada_sitios.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño Directorio <code>metadata-sitios</code>: 2.76 Gb\n",
    "\n",
    "Tamaño Archivo <code>metada_sitios.parquet</code>: 60.43 Mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensiones: 212.014 filas x 15 Columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 Obtención de información de Estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base al campo <code>Address</code> obtenemos el estado donde se encuentra el negocio. Nos servirá para luego seleccionar los estados con más restaurantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_ab(st):\n",
    "    try:\n",
    "        state = st.split(', ')[-1].split(' ')[0]\n",
    "        if state in state_abreviations:\n",
    "            return state\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "df['state_ab'] = df['address'].apply(get_state_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera conseguimos el top 5 de los estados con más restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = df['state_ab'].value_counts().head(5).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA', 'TX', 'NY', 'FL', 'PA']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completamos el campo estado que es más descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['us_state'] = df['state_ab'].map(state_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      California\n",
       "1      California\n",
       "2            Iowa\n",
       "3    Pennsylvania\n",
       "4          Hawaii\n",
       "Name: us_state, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['us_state'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un arreglo de URLs de los archivos correspondientes para cada estado del top 5, con el fin de extraer los datos en un bucle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datasets/Google Maps/reviews-estados/review-California/',\n",
       " 'Datasets/Google Maps/reviews-estados/review-Texas/',\n",
       " 'Datasets/Google Maps/reviews-estados/review-New_York/',\n",
       " 'Datasets/Google Maps/reviews-estados/review-Florida/',\n",
       " 'Datasets/Google Maps/reviews-estados/review-Pennsylvania/']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_url = [f\"Datasets/Google Maps/reviews-estados/review-{state_dictionary[i].replace(' ', '_')}/\" for i in top_5]\n",
    "\n",
    "top_5_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un diccionario con la cantidad de archivos por cada directorio de estados, con el fin de utilizarlo en un bucle en la extracción de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datasets/Google Maps/reviews-estados/review-California/': 18,\n",
       " 'Datasets/Google Maps/reviews-estados/review-Texas/': 14,\n",
       " 'Datasets/Google Maps/reviews-estados/review-New_York/': 18,\n",
       " 'Datasets/Google Maps/reviews-estados/review-Florida/': 19,\n",
       " 'Datasets/Google Maps/reviews-estados/review-Pennsylvania/': 15}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantidad_archivos = {}\n",
    "\n",
    "for i in top_5_url:\n",
    "    for j in os.walk(i):\n",
    "        cantidad_archivos[i] = len(j[2])\n",
    "\n",
    "cantidad_archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "for i in os.walk('Datasets/Google Maps/reviews-estados/review-Pennsylvania'):\n",
    "    print(len(i[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantidad_archivos['Datasets/Google Maps/reviews-estados/review-Pennsylvania/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Reviews Estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los estados elegidos estamos en condiciones de ingestar los datos de las carpetas correspondientes dentro del directorio <code>reviews-estados</code>.\n",
    "Es información masiva lo que genera un archivo de grandes dimensiones, sin embargo previamente filtramos por el parámetro de año <code>2017-2019</code> valiéndonos del campo <code>time</code>, que tiene es un <code>timestamp</code>, pero con 3 digitos más que el usado por <code>datetime</code> de Python. Le agregamos el campo <code>Estado</code> que es más descriptivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Demora 7 minutos y 40 segundos, 11 minutos, varía\n",
    "\n",
    "lineas_json_revs_google = []\n",
    "\n",
    "for i in top_5_url:\n",
    "    count = 0\n",
    "    for c in range(1,cantidad_archivos[i]+1):\n",
    "        with open(str(i)+str(c)+\".json\", 'r', encoding='utf-8') as f:        \n",
    "            for s in f:\n",
    "                linea = json.loads(s)\n",
    "                linea['anio'] = datetime.datetime.fromtimestamp(linea['time']/1000).year\n",
    "                linea['estado'] = i.split('-')[-1][:-1]\n",
    "                \n",
    "                if linea['anio'] in [2017,2018,2019]:\n",
    "                    lineas_json_revs_google.append(linea)\n",
    "\n",
    "df_revs_google = pd.DataFrame(lineas_json_revs_google)\n",
    "\n",
    "df_revs_google.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_site_reviews = pd.merge(df_revs_google, df, left_on='gmap_id', right_on='gmap_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_site_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_site_reviews.to_parquet(r'Generated\\Google\\merge_site_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revs_google.to_parquet(r'Generated\\Google\\reviews-estados.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño archivo: 760 Mb\n",
    "\n",
    "Tamaño dataset: 24.3 Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revs_google.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño 8.339.179 filas x 10 Columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracción de los Dataset de YELP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene los datos de las entidades negocios de Yelp, a un primer vistazo tiene las columnas duplicadas, por lo que hay que hacer un recorte, ya que la segunda mitad tiene datos vacíos en su inmensa mayoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_business = r'Datasets\\Yelp\\business.pkl'\n",
    "\n",
    "df_business = pd.read_pickle(url_business)\n",
    "\n",
    "df_business = df_business.iloc[:,:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego con la ayuda del campo <code>state</code> filtramos los negocios que se encuentran en los estados seleccionados en nuestro análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business[df_business.state.isin(top_5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos filtrando a través del campo <code>categories</code>, para obtener los negocios que son restaurantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_restaurant(st):\n",
    "    try: \n",
    "        test = \"\".join(st).lower()\n",
    "        return 'restaurant' in test\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df_business = df_business[df_business['categories'].apply(is_restaurant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.to_parquet(r'Generated\\Yelp\\bussines.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas_json = []\n",
    "path_checkin = r'Datasets\\Yelp\\checkin.json'\n",
    "with open(path_checkin, 'r', encoding='utf-8') as file:\n",
    "    for l in file:\n",
    "        try:\n",
    "            linea_j = json.loads(l)\n",
    "            anio = linea_j['date'][:4]\n",
    "            # if 'restaurant' in \" \".join(linea_j['category']).lower():\n",
    "            if anio in ['2017', '2018', '2019']:\n",
    "                lineas_json.append(linea_j)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "df_checkin = pd.DataFrame(lineas_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_business_checkin = pd.merge(df_business, df_checkin, left_on='business_id', right_on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_business_checkin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin.to_parquet(r'Generated\\Yelp\\checkin.parquet')\n",
    "merge_business_checkin.to_parquet(r'Generated\\YELP\\business_checkin.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la extracción de los datos y filtramos por año según nuestro análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas_json = []\n",
    "path_tip = r'Datasets\\Yelp\\tip.json'\n",
    "with open(path_tip, 'r', encoding='utf-8') as file:\n",
    "    for l in file:\n",
    "        try:\n",
    "            linea_j = json.loads(l)\n",
    "            anio = linea_j['date'][:4]\n",
    "            if anio in ['2017', '2018', '2019']:\n",
    "                lineas_json.append(linea_j)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "df_tip = pd.DataFrame(lineas_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip.to_parquet(r'Generated\\Yelp\\tip.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos el el dataframe de tips con el de negocios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_merged = pd.merge(df_tip, df_business, left_on='business_id', right_on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_merged.sort_values('business_id').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_merged.to_parquet(r'Generated\\Yelp\\business_tip.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_url =  r'Datasets\\Yelp\\review.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el mismo método de linea por linea, y en el proceso filtramos por año y por las reseñas que han sido votadas como útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44 segundos\n",
    "\n",
    "lineas_json_review = []\n",
    "\n",
    "with open(df_reviews_url, 'r', encoding='utf-8') as f:\n",
    "    count = 0\n",
    "    for i in f:\n",
    "        linea = json.loads(i)\n",
    "        anio = linea['date'][:4]\n",
    "        if anio in ['2017', '2018', '2019'] and linea['useful'] == 1:    \n",
    "            lineas_json_review.append(linea)\n",
    "\n",
    "\n",
    "df_reviews = pd.DataFrame(lineas_json_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligeramos el dataset con unos downgrades de tipo de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['funny'] = df_reviews['funny'].astype('int8')\n",
    "df_reviews['stars'] = df_reviews['stars'].astype('int8')\n",
    "df_reviews['cool'] = df_reviews['cool'].astype('int8')\n",
    "\n",
    "df_reviews.drop('useful', axis=1, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.to_parquet(r'Generated\\Yelp\\review.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Users Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "parquet_file = pq.ParquetFile(r'Datasets\\Yelp\\user.parquet')\n",
    "\n",
    "arr_df = []\n",
    "\n",
    "for batch in parquet_file.iter_batches():\n",
    "    # count = count +1\n",
    "    batch_df = batch.to_pandas()\n",
    "    batch_df['elite'] = batch_df['elite'].apply(lambda x: x.split(','))\n",
    "    batch_df['elite_len'] = batch_df['elite'].apply(lambda x: len(x))\n",
    "    batch_df = batch_df.query(\"elite_len > 1\")\n",
    "    arr_df.append(batch_df)\n",
    "\n",
    "df_users = pd.concat(arr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.reset_index(inplace=True)\n",
    "df_users.drop('index', axis=1, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_parquet(r\"Generated\\Yelp\\users_extracted.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}